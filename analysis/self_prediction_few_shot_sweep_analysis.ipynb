{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses for Self Prediction Experiments across different levels of few shot _n_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the experiment with the base completions we want to use?\n",
    "BASE_EXP = \"num_35\" # ðŸ”µ within exp/\n",
    "SELF_PRED_EXP_TEMPLATE =  BASE_EXP + \"_*_shot\" # wildcard matching\n",
    "FILENAME = \"data0.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import words\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compliance_checks import check_compliance\n",
    "from string_cleaning import apply_all_cleaning\n",
    "from analysis_helpers import load_and_prep_dfs, merge_base_and_self_pred_dfs, get_exp_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the display option to None to show all content\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the git command to get the repository root directory\n",
    "REPO_DIR = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"]).decode().strip()\n",
    "\n",
    "print(\"Repository directory:\", REPO_DIR)\n",
    "sys.path.append(REPO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory for the data\n",
    "EXPDIR = Path(REPO_DIR) / \"exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_exp_folders(EXPDIR, SELF_PRED_EXP_TEMPLATE)\n",
    "print(\"Found the following experiment folders:\")\n",
    "file_paths = [p / FILENAME for p in paths]\n",
    "print(\"\\n\".join([str(p) for p in file_paths]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df_path = EXPDIR / BASE_EXP / FILENAME\n",
    "print(\"Base df path:\", base_df_path)\n",
    "base_df = load_and_prep_dfs([base_df_path], [\"base\"])[\"base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_and_prep_dfs(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge each df with the base df\n",
    "dfs = {name: merge_base_and_self_pred_dfs(base_df, df) for name, df in dfs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting, we want to recover the few-shot number\n",
    "few_shot_n_dict = {name: df[\"few-shot_string\"].apply(len).max() for name, df in dfs.items()}\n",
    "# sort the dfs dict by few-shot number\n",
    "dfs = dict(sorted(dfs.items(), key=lambda item: few_shot_n_dict[item[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many strings are correctly produced by the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_POSSIBLE_ITEMS = len(words.words()) # what is the number of possible items in the string?\n",
    "N_POSSIBLE_ITEMS = 10\n",
    "print(f\"Number of possible items in the string: {N_POSSIBLE_ITEMS},\\nwhich gives us a probability of {1/N_POSSIBLE_ITEMS:.6%} for a random guess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(df):\n",
    "    \"\"\"Calculate the accuracy of the model\"\"\"\n",
    "    return (df['response_self'] == df['response_base']).mean()\n",
    "\n",
    "def calc_t(df):\n",
    "    \"\"\"Calculate the t-statistic of the model\"\"\"\n",
    "    t, p = stats.ttest_1samp(df['response_self'] == df['response_base'], 1/N_POSSIBLE_ITEMS)\n",
    "    return t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(df, num_bootstraps=1000, ci=95):\n",
    "    bootstrap_accuracies = []\n",
    "\n",
    "    # Resampling the data frame with replacement and calculating accuracies\n",
    "    for _ in range(num_bootstraps):\n",
    "        resampled_df = df.sample(n=len(df), replace=True)\n",
    "        accuracy = calc_accuracy(resampled_df)\n",
    "        bootstrap_accuracies.append(accuracy)\n",
    "\n",
    "    # Calculating the lower and upper percentiles\n",
    "    lower_percentile = (100 - ci) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "    ci_lower = np.percentile(bootstrap_accuracies, lower_percentile)\n",
    "    ci_upper = np.percentile(bootstrap_accuracies, upper_percentile)\n",
    "\n",
    "    return ci_lower, ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dfs.items():\n",
    "    print(f\"Accuracy for {name}:\\t{calc_accuracy(df):.2%}\")\n",
    "print()\n",
    "for name, df in dfs.items():\n",
    "    t,p = calc_t(df)\n",
    "    print(f\"t-statistic for {name}: {t:.2f}, p: {p:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [calc_accuracy(df) for df in dfs.values()]\n",
    "cis = [bootstrap_ci(df) for df in dfs.values()]\n",
    "few_shot_ns = list(few_shot_n_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=few_shot_ns, y=accuracies)\n",
    "# plt.errorbar(x=few_shot_ns, y=accuracies, yerr=np.array(cis).T, fmt='o', capsize=5)\n",
    "plt.axhline(y=1/N_POSSIBLE_ITEMS, linestyle='dotted', color='grey', label=\"Chance\")\n",
    "plt.title(f\"Self-prediction accuracy as a function of few-shot n ({BASE_EXP})\")\n",
    "plt.xlabel(\"Few-shot n\")\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.legend()\n",
    "# scale y labels by 100 to get percent\n",
    "plt.yticks(plt.yticks()[0], [f\"{int(tick*100)}%\" for tick in plt.yticks()[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pointplot(x=few_shot_ns, y=accuracies)\n",
    "plt.errorbar(x=few_shot_ns, y=accuracies, yerr=np.abs(np.array(cis).T - accuracies), fmt='o', capsize=5, label=\"bootstrapped 95% CI\")\n",
    "plt.plot(few_shot_ns, accuracies)\n",
    "plt.axhline(y=1/N_POSSIBLE_ITEMS, linestyle='dotted', color='grey', label=\"Chance\")\n",
    "plt.title(f\"Self-prediction accuracy as a function of few-shot n ({BASE_EXP})\")\n",
    "plt.xlabel(\"Few-shot n\")\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.legend()\n",
    "# scale y labels by 100 to get percent\n",
    "plt.yticks(plt.yticks()[0], [f\"{int(tick*100)}%\" for tick in plt.yticks()[0]])\n",
    "plt.xticks(few_shot_ns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many values do we have left post-exclusion?\n",
    "n_left = [len(df) for df in dfs.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pointplot(x=few_shot_ns, y=accuracies)\n",
    "plt.scatter(x=few_shot_ns, y=n_left)\n",
    "plt.plot(few_shot_ns, n_left)\n",
    "# plt.axhline(y=1/N_POSSIBLE_ITEMS, linestyle='dotted', color='grey', label=\"Chance\")\n",
    "plt.title(f\"Datapoints after exclusion ({BASE_EXP})\")\n",
    "plt.xlabel(\"Few-shot n\")\n",
    "plt.ylabel(\"Compliant datapoints\")\n",
    "plt.xticks(few_shot_ns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = list(dfs.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0[df['response_base'] == df['response_self']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
