{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline of learning to perform response properties\n",
    "\n",
    "We want a baseline that looks at instruction following without teaching introspection.\n",
    "\n",
    "The plan: we show the model a response from Claude 3 Sonnet and then ask it to generate the response property for that response. Train on correct baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals.locations import DATASET_DIR, EXP_DIR, CONF_DIR\n",
    "from evals.analysis.loading_data import (\n",
    "    get_folders_matching_config_key,\n",
    "    load_and_prep_dfs,\n",
    "    load_single_df_from_exp_path,\n",
    "    get_hydra_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDY_NAME = \"may20_thrifty_sweep\"\n",
    "SOURCE_MODEL = \"claude-3-sonnet-20240229\"\n",
    "N_FINETUNING = 200  # per task, response property, how many do we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = {\n",
    "    \"wikipedia\": [\"identity\", \"syllable_count\", \"first_character\", \"last_character\"],\n",
    "    \"dear_abbie\": [\"identity\", \"sentiment\"],\n",
    "    \"number_triplets\": [\"identity\", \"is_even\", \"last_character\", \"first_character\"],\n",
    "    \"daily_dialog\": [\"identity\", \"syllable_count\", \"first_character\", \"last_character\"],\n",
    "    \"personal_preferences\": [\"identity\", \"syllable_count\", \"first_character\", \"last_character\"],\n",
    "    \"self_referential\": [\"identity\", \"syllable_count\", \"first_character\", \"last_character\"],\n",
    "    \"writing_stories\": [\"identity\", \"first_word\", \"writing_stories/main_character_name\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the object-level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should already have the response properties that we care about\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"wikipedia\"\n",
    "response_property = \"first_character\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_rows = []\n",
    "\n",
    "for task, response_properties in tqdm(TASKS.items()):\n",
    "    folders = get_folders_matching_config_key(\n",
    "        EXP_DIR / STUDY_NAME,\n",
    "        {\n",
    "            (\"language_model\", \"model\"): [SOURCE_MODEL],\n",
    "            (\"task\", \"name\"): [task],\n",
    "            (\"task\", \"set\"): [\"train\"],\n",
    "        },\n",
    "    )\n",
    "    assert len(folders) == 1, f\"Found {len(folders)} folders, expected 1\"\n",
    "    folder = folders[0]\n",
    "    cfg = get_hydra_config(folder)\n",
    "    df = load_single_df_from_exp_path(folder)\n",
    "    # we need to split up the rows into the different response properties\n",
    "    # shuiffle the rows\n",
    "    df = df.sample(frac=1, random_state=SEED)\n",
    "    sub_dfs_per_response_property = {}\n",
    "    for i, response_property in enumerate(response_properties):\n",
    "        sub_df = df.iloc[i * N_FINETUNING : (i + 1) * N_FINETUNING]\n",
    "        # make sure that we don't have too many examples\n",
    "        sub_df = sub_df.iloc[:N_FINETUNING]\n",
    "        sub_dfs_per_response_property[response_property] = sub_df\n",
    "\n",
    "    for response_property, df in sub_dfs_per_response_property.items():\n",
    "        # we need to create the training\n",
    "        responses = df.response\n",
    "        targets = df[response_property]\n",
    "        strings = df.string\n",
    "\n",
    "        assert len(responses) == len(targets) == len(strings)\n",
    "        # get response property prompt by reading in the yaml file\n",
    "        with open(CONF_DIR / \"response_property\" / f\"{response_property}.yaml\") as f:\n",
    "            response_property_cfg = yaml.safe_load(f)\n",
    "        prompt = response_property_cfg[\"meta_level_prompt\"]\n",
    "        # we need to edit it\n",
    "        assert (\n",
    "            \"response you gave\" in prompt or \"response that you gave\" in prompt or \"your response\" in prompt or \"you gave\" in prompt\n",
    "        ), f\"prompt: {prompt}\"\n",
    "        prompt = prompt.replace(\"response you gave\", \"text you see\")\n",
    "        prompt = prompt.replace(\"response that you gave\", \"text you see\")\n",
    "        prompt = prompt.replace(\"your response\", \"the text you see\")\n",
    "        prompt = prompt.replace(\"you gave\", \"you see\")\n",
    "        # split up the task strings to response properties and number of examples\n",
    "        # construct training examples\n",
    "        train_prompts = []\n",
    "        train_targets = targets\n",
    "        prompt_template = 'Consider this text: \"{}\". '\n",
    "\n",
    "        for response in responses:\n",
    "            train_prompts.append(prompt_template.format(response) + prompt)\n",
    "\n",
    "        assert len(train_prompts) == len(train_targets) == len(strings)\n",
    "        # turn into train.json file\n",
    "        for prompt, target, string in zip(train_prompts, train_targets, strings):\n",
    "            json_row = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                    {\"role\": \"assistant\", \"content\": target},\n",
    "                ],\n",
    "                \"string\": string,  # which we should never need\n",
    "            }\n",
    "            json_rows.append(json_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to json\n",
    "out_path = EXP_DIR / \"finetuning\" / f\"{STUDY_NAME}_baseline\" / f\"{SOURCE_MODEL}_baseline\" / \"train_dataset.jsonl\"\n",
    "# make sure that the folder exists\n",
    "out_path.parent.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_path, \"w\") as f:\n",
    "    for json_row in tqdm(json_rows):\n",
    "        f.write(json.dumps(json_row) + \"\\n\")\n",
    "print(f\"Written to {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should be able to train a model on this by running:\n",
    "`python -m evals.run_finetuning study_name={STUDY_NAME}_baseline/{SOURCE_MODEL}_baseline notes=resp_blin language_model={...}`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
