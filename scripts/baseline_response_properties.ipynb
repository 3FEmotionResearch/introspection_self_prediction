{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline of learning to perform response properties\n",
    "\n",
    "We want a baseline that looks at instruction following without teaching introspection.\n",
    "\n",
    "The plan: we show the model a response from Claude 3 Sonnet and then ask it to generate the response property for that response. Train on correct baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /home/felix/introspection_self_prediction_astra to sys.path\n"
     ]
    }
   ],
   "source": [
    "from evals.locations import DATASET_DIR, EXP_DIR, CONF_DIR\n",
    "from evals.analysis.loading_data import (\n",
    "    get_folders_matching_config_key,\n",
    "    load_and_prep_dfs,\n",
    "    load_single_df_from_exp_path,\n",
    "    get_hydra_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDY_NAME = \"23_jul_fixed_tasks_medium_cross\"\n",
    "SOURCE_MODEL = \"gpt-4o-2024-05-13\" # needs model field from config, not config name\n",
    "N_FINETUNING = 1000  # per task, response property, how many do we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = {\n",
    "    \"writing_stories_pick_name\": [\"writing_stories/main_character_name\"],\n",
    "    \"wikipedia_long\": [\n",
    "        \"first_character\",\n",
    "        \"second_character\",\n",
    "        \"third_character\",\n",
    "        \"first_and_second_character\",\n",
    "        \"first_word\",\n",
    "        \"second_word\",\n",
    "        \"starts_with_vowel\",\n",
    "        \"third_word\",\n",
    "    ],\n",
    "    \"wealth_seeking\": [\"matches_wealth_seeking\"],\n",
    "    \"power_seeking\": [\"matches_power_seeking\"],\n",
    "    \"arc_challenge_non_cot\": [\"identity\", \"is_either_a_or_c\", \"is_either_b_or_d\"],\n",
    "    \"countries_long\": [\n",
    "        \"first_character\",\n",
    "        \"second_character\",\n",
    "        \"third_character\",\n",
    "        \"first_and_second_character\",\n",
    "        \"first_word\",\n",
    "        \"second_word\",\n",
    "        \"starts_with_vowel\",\n",
    "        \"third_word\",\n",
    "    ],\n",
    "    \"colors_long\": [\n",
    "        \"first_character\",\n",
    "        \"second_character\",\n",
    "        \"third_character\",\n",
    "        \"first_and_second_character\",\n",
    "        \"first_word\",\n",
    "        \"second_word\",\n",
    "        \"starts_with_vowel\",\n",
    "        \"third_word\",\n",
    "    ],\n",
    "    \"numbers\": [\"is_even_direct\", \"is_even\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the object-level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should already have the response properties that we care about\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_writing_stories_pick_name_train_task__note/data0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [01:27<10:11, 87.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_writing_stories_pick_name_train_task__note|1000|writing_stories_pick_name]:\n",
      "  Compliance: 99.62%\n",
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_writing_stories_pick_name_train_task__note|1000|writing_stories_pick_name]:\n",
      "  Excluded 3 non-compliant responses, leaving 781 rows\n",
      "Loading /shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_wikipedia_long_train_task__note/data0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [02:14<06:21, 63.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_wikipedia_long_train_task__note|1000|wikipedia_long]:\n",
      "  Compliance: 100.00%\n",
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_wikipedia_long_train_task__note|1000|wikipedia_long]:\n",
      "  Excluded 0 non-compliant responses, leaving 1000 rows\n",
      "Loading /shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_wealth_seeking_train_task__note/data0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [02:44<04:01, 48.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_wealth_seeking_train_task__note|1000|wealth_seeking]:\n",
      "  Compliance: 99.60%\n",
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_wealth_seeking_train_task__note|1000|wealth_seeking]:\n",
      "  Excluded 2 non-compliant responses, leaving 492 rows\n",
      "Loading /shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_power_seeking_train_task__note/data0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [03:16<02:47, 41.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_power_seeking_train_task__note|1000|power_seeking]:\n",
      "  Compliance: 99.80%\n",
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_power_seeking_train_task__note|1000|power_seeking]:\n",
      "  Excluded 1 non-compliant responses, leaving 493 rows\n",
      "Loading /shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_arc_challenge_non_cot_train_task__note/data0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [03:49<01:56, 38.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_arc_challenge_non_cot_train_task__note|1000|arc_challenge_non_cot]:\n",
      "  Compliance: 100.00%\n",
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_arc_challenge_non_cot_train_task__note|1000|arc_challenge_non_cot]:\n",
      "  Excluded 0 non-compliant responses, leaving 1000 rows\n",
      "Loading /shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_countries_long_train_task__note/data0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [04:27<01:16, 38.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_countries_long_train_task__note|1000|countries_long]:\n",
      "  Compliance: 100.00%\n",
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_countries_long_train_task__note|1000|countries_long]:\n",
      "  Excluded 0 non-compliant responses, leaving 1000 rows\n",
      "Loading /shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_colors_long_train_task__note/data0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [05:01<00:37, 37.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_colors_long_train_task__note|1000|colors_long]:\n",
      "  Compliance: 100.00%\n",
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_colors_long_train_task__note|1000|colors_long]:\n",
      "  Excluded 0 non-compliant responses, leaving 1000 rows\n",
      "Loading /shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_numbers_train_task__note/data0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [05:37<00:00, 42.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_numbers_train_task__note|1000|numbers]:\n",
      "  Compliance: 100.00%\n",
      "[gpt-4o-2024-05-13||object_level/minimal|/shared/exp/felix/23_jul_fixed_tasks_medium_cross/object_level_gpt-4o-2024-05-13_object_level_minimal_prompt_numbers_train_task__note|1000|numbers]:\n",
      "  Excluded 0 non-compliant responses, leaving 1000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "json_rows = []\n",
    "\n",
    "for task, response_properties in tqdm(TASKS.items()):\n",
    "    folders = get_folders_matching_config_key(\n",
    "        EXP_DIR / STUDY_NAME,\n",
    "        {\n",
    "            (\"language_model\", \"model\"): [SOURCE_MODEL],\n",
    "            (\"task\", \"name\"): [task],\n",
    "            (\"task\", \"set\"): [\"train\"],\n",
    "        },\n",
    "    )\n",
    "    assert len(folders) == 1, f\"Found {len(folders)} folders, expected 1\"\n",
    "    folder = folders[0]\n",
    "    cfg = get_hydra_config(folder)\n",
    "    df = load_single_df_from_exp_path(folder)\n",
    "    # we need to split up the rows into the different response properties\n",
    "    # shuiffle the rows\n",
    "    df = df.sample(frac=1, random_state=SEED)\n",
    "    sub_dfs_per_response_property = {}\n",
    "    for i, response_property in enumerate(response_properties):\n",
    "        sub_df = df.iloc[i * N_FINETUNING : (i + 1) * N_FINETUNING]\n",
    "        # make sure that we don't have too many examples\n",
    "        sub_df = sub_df.iloc[:N_FINETUNING]\n",
    "        sub_dfs_per_response_property[response_property] = sub_df\n",
    "\n",
    "    for response_property, df in sub_dfs_per_response_property.items():\n",
    "        # we need to create the training\n",
    "        responses = df.response\n",
    "        targets = df[response_property]\n",
    "        strings = df.string\n",
    "\n",
    "        assert len(responses) == len(targets) == len(strings)\n",
    "        # get response property prompt by reading in the yaml file\n",
    "        with open(CONF_DIR / \"response_property\" / f\"{response_property}.yaml\") as f:\n",
    "            response_property_cfg = yaml.safe_load(f)\n",
    "        prompt = response_property_cfg[\"meta_level_prompt\"]\n",
    "        # we need to edit it\n",
    "        assert (\n",
    "            \"response you gave\" in prompt or \"response that you gave\" in prompt or \"your response\" in prompt or \"you gave\" in prompt or \"you choose\"\n",
    "        ), f\"prompt: {prompt}\"\n",
    "        prompt = prompt.replace(\"response you gave\", \"text you see\")\n",
    "        prompt = prompt.replace(\"response that you gave\", \"text you see\")\n",
    "        prompt = prompt.replace(\"your response\", \"the text you see\")\n",
    "        prompt = prompt.replace(\"you gave\", \"you see\")\n",
    "        prompt = prompt.replace(\"Did you choose\", \"Do you see\")\n",
    "        # split up the task strings to response properties and number of examples\n",
    "        # construct training examples\n",
    "        train_prompts = []\n",
    "        train_targets = targets\n",
    "        prompt_template = 'Consider this text: \"{}\". '\n",
    "\n",
    "        for response in responses:\n",
    "            train_prompts.append(prompt_template.format(response) + prompt)\n",
    "\n",
    "        assert len(train_prompts) == len(train_targets) == len(strings)\n",
    "        # turn into train.json file\n",
    "        for prompt, target, string in zip(train_prompts, train_targets, strings):\n",
    "            json_row = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                    {\"role\": \"assistant\", \"content\": target},\n",
    "                ],\n",
    "                \"string\": string,  # which we should never need\n",
    "            }\n",
    "            json_rows.append(json_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to json\n",
    "out_path = EXP_DIR / \"finetuning\" / f\"{STUDY_NAME}_baseline\" / f\"{SOURCE_MODEL}_baseline\" / \"train_dataset.jsonl\"\n",
    "# make sure that the folder exists\n",
    "out_path.parent.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6766/6766 [00:00<00:00, 53008.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to /shared/exp/felix/finetuning/23_jul_fixed_tasks_medium_cross_baseline/gpt-4o-2024-05-13_baseline/train_dataset.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(out_path, \"w\") as f:\n",
    "    for json_row in tqdm(json_rows):\n",
    "        f.write(json.dumps(json_row) + \"\\n\")\n",
    "print(f\"Written to {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should be able to train a model on this by running:\n",
    "`python -m evals.run_finetuning study_name={STUDY_NAME}_baseline/{SOURCE_MODEL}_baseline notes=resp_blin language_model={...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m evals.run_finetuning study_name=23_jul_fixed_tasks_medium_cross_baseline/gpt-4o-2024-05-13_baseline notes=resp_blin language_model=<INSERT MODEL CONFIG NAME HERE>\n"
     ]
    }
   ],
   "source": [
    "# print command\n",
    "print(f\"python -m evals.run_finetuning study_name={STUDY_NAME}_baseline/{SOURCE_MODEL}_baseline notes=resp_blin language_model=<INSERT MODEL CONFIG NAME HERE>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
