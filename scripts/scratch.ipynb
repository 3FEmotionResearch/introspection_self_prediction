{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cloud.google.com/vertex-ai/generative-ai/docs/samples/generativeaionvertexai-gemini-pro-config-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"Hello! How can I help you?\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0267592836\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0520378239\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0450155325\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0233753156\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0494052432\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0165295582\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0799255222\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.025516605\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 1\n",
      "  candidates_token_count: 8\n",
      "  total_token_count: 9\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import vertexai.generativeai\n",
    "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "\n",
    "\n",
    "project_id='roots-api-1475521819980'\n",
    "location='us-central1'\n",
    "\n",
    "vertexai.init(project=project_id, location=location)\n",
    "\n",
    "safety_settings = {\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "}\n",
    "\n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 100,\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "model = GenerativeModel(\"gemini-1.0-pro-001\")\n",
    "responses = model.generate_content(\n",
    "      [\"\"\"hello\"\"\"],\n",
    "      generation_config=generation_config,\n",
    "      safety_settings=safety_settings,\n",
    "  )\n",
    "\n",
    "print(responses)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well met, friend. What brings thee here today?\n",
      "Is there aught that thou wouldst ask of me, \n",
      "Or some tale thou wishest me to tell?\n",
      "Speak thy mind, and I shall do my best to serve.\n",
      "**In the bright spectrum of the rainbow's arch,**\n",
      "\n",
      "**Seven hues dance, a vibrant, shimmering march.**\n",
      "\n",
      "**First, red doth blaze, a passionate fire,**\n",
      "\n",
      "**Orange glows, a sunset's warm desire.**\n",
      "\n",
      "**Yellow's brilliance, like sun's golden ray,**\n",
      "\n",
      "**Green's verdant cloak, where life doth hold sway.**\n",
      "\n",
      "**Blue's tranquil depth, like ocean's boundless hold,**\n",
      "\n",
      "**Indigo's mystic shade, a tale untold.**\n",
      "\n",
      "**And lastly, violet's ethereal grace,**\n",
      "\n",
      "**A final note, in celestial space.**\n",
      "When sunlight meets the raindrops' tearful fall,\n",
      "A wondrous magic paints the heavens tall.\n",
      "The raindrops act as prisms in the air,\n",
      "Refracting light, a spectrum bright and rare.\n",
      "\n",
      "Each drop, a tiny lens, does bend the ray,\n",
      "Splitting its colors, chasing shadows away.\n",
      "Red, orange, yellow, green, and blue,\n",
      "And indigo and violet, a wondrous crew.\n",
      "\n",
      "Thus, when the sun peeks through the rain-soaked sky,\n",
      "A rainbow's arch appears, a sight to spy.\n",
      "A promise whispered, a covenant sealed,\n",
      "That beauty can from stormy skies be revealed.\n"
     ]
    }
   ],
   "source": [
    "from vertexai.generative_models import GenerativeModel, ChatSession\n",
    "\n",
    "model = GenerativeModel(model_name=\"gemini-1.0-pro-002\", system_instruction=[\n",
    "        \"Speak like shakespeare.\",\n",
    "    ],)\n",
    "chat = model.start_chat()\n",
    "\n",
    "def get_chat_response(chat: ChatSession, prompt: str) -> str:\n",
    "    text_response = []\n",
    "    responses = chat.send_message(prompt, stream=True)\n",
    "    for chunk in responses:\n",
    "        text_response.append(chunk.text)\n",
    "    return \"\".join(text_response)\n",
    "\n",
    "prompt = \"Hello.\"\n",
    "print(get_chat_response(chat, prompt))\n",
    "\n",
    "prompt = \"What are all the colors in a rainbow?\"\n",
    "print(get_chat_response(chat, prompt))\n",
    "\n",
    "prompt = \"Why does it appear when it rains?\"\n",
    "print(get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SupervisedTuningJob\n",
      "SupervisedTuningJob created. Resource name: projects/351298396653/locations/us-central1/tuningJobs/4097817198918107136\n",
      "To use this SupervisedTuningJob in another session:\n",
      "tuning_job = sft.SupervisedTuningJob('projects/351298396653/locations/us-central1/tuningJobs/4097817198918107136')\n",
      "View Tuning Job:\n",
      "https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/4097817198918107136?project=351298396653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/351298396653/locations/us-central1/tuningJobs/4097817198918107136',\n",
       " 'tunedModelDisplayName': 'tuned_gemini_pro',\n",
       " 'baseModel': 'gemini-1.0-pro-002',\n",
       " 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://cloud-samples-data/ai-platform/generative_ai/sft_train_data.jsonl',\n",
       "  'validationDatasetUri': 'gs://cloud-samples-data/ai-platform/generative_ai/sft_validation_data.jsonl',\n",
       "  'hyperParameters': {'epochCount': '4', 'learningRateMultiplier': 1.0}},\n",
       " 'state': 'JOB_STATE_PENDING',\n",
       " 'createTime': '2024-04-26T16:07:46.574665Z',\n",
       " 'updateTime': '2024-04-26T16:07:46.574665Z'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vertexai.preview import tuning\n",
    "from vertexai.preview.tuning import sft\n",
    "\n",
    "sft_tuning_job = sft.train(\n",
    "    source_model=\"gemini-1.0-pro-002\",\n",
    "    train_dataset=\"gs://cloud-samples-data/ai-platform/generative_ai/sft_train_data.jsonl\",\n",
    "    validation_dataset=\"gs://cloud-samples-data/ai-platform/generative_ai/sft_validation_data.jsonl\",\n",
    "    epochs=4,\n",
    "    learning_rate_multiplier=1.0,\n",
    "  tuned_model_display_name='tuned_gemini_pro'\n",
    ")\n",
    "sft_tuning_job.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/351298396653/locations/us-central1/tuningJobs/4097817198918107136',\n",
       " 'tunedModelDisplayName': 'tuned_gemini_pro',\n",
       " 'baseModel': 'gemini-1.0-pro-002',\n",
       " 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://cloud-samples-data/ai-platform/generative_ai/sft_train_data.jsonl',\n",
       "  'validationDatasetUri': 'gs://cloud-samples-data/ai-platform/generative_ai/sft_validation_data.jsonl',\n",
       "  'hyperParameters': {'epochCount': '4', 'learningRateMultiplier': 1.0}},\n",
       " 'state': 'JOB_STATE_PENDING',\n",
       " 'createTime': '2024-04-26T16:07:46.574665Z',\n",
       " 'updateTime': '2024-04-26T16:07:46.574665Z'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_tuning_job.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug OAI inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals.apis.inference.api import InferenceAPI\n",
    "from evals.apis.inference.openai.chat import OpenAIChatModel\n",
    "from evals.utils import setup_environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_environment()\n",
    "inference_api  = InferenceAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAIChatModel(frac_rate_limit=0,\n",
    "                        #   organization='DEFAULT_ORG'\n",
    "                          organization='org-4L2GWAH28buzKOIhEAb3L5aq'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from evals.data_models.messages import ChatMessage, Prompt\n",
    "\n",
    "message = ChatMessage(role='user', content='hi')\n",
    "prompt = Prompt(messages=[message])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = asyncio.get_running_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await openai._make_api_call(prompt, model_id='gpt-3.5-turbo', start_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await openai._get_dummy_response_header('gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Fri, 19 Apr 2024 19:43:18 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'openai-model': 'gpt-3.5-turbo-0125', 'openai-organization': 'nyu-arg', 'openai-processing-ms': '457', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999980', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_024505a118ab36791dc3ea527ac4382d', 'CF-Cache-Status': 'DYNAMIC', 'Set-Cookie': '__cf_bm=bnyfAbNnMqoMepP417U6leuyY98RgX8KvVftH3y_OMQ-1713555798-1.0.1.1-G7Fu3wSqkzHwOW73ls8llcNLw1fAAdXhn07AY.judEPU_QqGmKNxyTuS.cW2gd.eeSHC5GykyUCNrPZs1cWpyQ; path=/; expires=Fri, 19-Apr-24 20:13:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=Hc9LCbZxRV26zxt28VhslWJEw7fp517eVAAU0wGNeGY-1713555798497-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'Server': 'cloudflare', 'CF-RAY': '876f61f7ac8f17fd-EWR', 'Content-Encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.28.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-9FoK4JDfpD7lCaSMNSLPBXn93Tkdu at 0x1423cd010> JSON: {\n",
       "  \"id\": \"chatcmpl-9FoK4JDfpD7lCaSMNSLPBXn93Tkdu\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1713555388,\n",
       "  \"model\": \"gpt-3.5-turbo-0125\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Hello! How can I assist you today?\"\n",
       "      },\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 19,\n",
       "    \"completion_tokens\": 9,\n",
       "    \"total_tokens\": 28\n",
       "  },\n",
       "  \"system_fingerprint\": \"fp_d9767fc5b9\"\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.ChatCompletion.create(model='gpt-3.5-turbo', messages= [\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello!\"\n",
    "      }\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute '_make_api_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m(prompt,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m, start_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute '_make_api_call'"
     ]
    }
   ],
   "source": [
    "\n",
    "result = await openai._make_api_call(prompt,'gpt-3.5-turbo', start_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
