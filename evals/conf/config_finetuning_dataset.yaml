hydra:
  run:
    dir: ${exp_dir}/logs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${exp_dir}/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job_logging:
    root:
      level: INFO

# when using, these values will be overwritten by the config files in the folder the data is created in.

defaults: # these should be overwritten in the particular finetuning files!
  - task: wikipedia
  - prompt: meta_level/minimal
  - response_property: identity

study_dir: exp/finetuning/${study_name} #??? # the folder of the study which contains multiple experiments

study_name: ??
base_dir: ??

exp_dir: ${sanitize:${study_dir}}

task:
  set: train # either all, train, or val. For finetuning, use train.

train_strings_path: none # overwrite to use fix the strings to use in training
val_strings_path: none # overwrite to use fix the strings to use in vaâ€”dation

limit: 1250 # default for the number of strings to use in training and validation together. Overwrite with limit in the config file in the finetuning folder

validation_fraction: 0.2 # fraction of the dataset to use for validation

seed: 0 # seed for the random number generator
