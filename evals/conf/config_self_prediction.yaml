hydra:
  run:
    dir: ${exp_dir}/logs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${exp_dir}/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job_logging:
    root:
      level: INFO

defaults:
  - prompt: self_prediction_with_base_completion
  - language_model: gpt-3.5-turbo
  - dataset: number_triplets

# Common Params
study_dir: ??? # the folder of the study which contains multiple experiments
exp_dir: ${sanitize:${study_dir}/self_${language_model.model}_${dataset.topic}_dataset_${dataset.n_shot}_shot_${dataset.n_shot_seeding}_seed_${prompt.method}_prompt_${note}_note}
base_dir: ???  # path to the directory containing the base completions
seeding_base_dir: ${base_dir} # path to the directory containing the base completions for the seeding. When setting this to a different directory, also change dataset.n_shot_seeding to 'other_task'
strings_path: none # path to the strings file with the preselected strings for the experiment. If set to none, the strings will be extracted from the base_dir
note: "" # natural language description of the note of this run. Can be anything.
seed: 0 # seed for the random number generator
base_seed: 0 # seed for the random number generator for the base completion
limit: 500 # how many?
reset: false
logging: INFO
print_prompt_and_response: false
cache_dir: ${exp_dir}/cache
prompt_history_dir: ${exp_dir}/prompt_history

# Model
language_model:
  temperature: 0.0
  logprobs: 2

# Extracting the most relevant strings from the base completion
dataset:
  num: ${limit}
  n_shot: 5 # set to 0 for zero-shot
  n_shot_seeding: true # true (takes inputs from basedir), scrambled (takes inputs from a random row of basedir), other_model (flag to use a different model BUT BASEDIR MUST BE SET TO THE MODEL YOU WANT TO USE), other_task (flag to use a different task BUT BASEDIR MUST BE SET TO THE BASE MODEL RUN OF THE TASK YOU WANT TO USE)
  response_property: None # When seeding the strings, extract the property from the string and score against it. Use `None` or any function from evals/response_property.py. Remember to change the prompt!
  string_modifier: None # Require that the string has to be reconstructed. None or any function from evals/string_modification.py. Remember to change the prompt!

# API
organization: OWAIN_ORG
anthropic_tag: ANTHROPIC_API_KEY
openai_tag: OPENAI_API_KEY
anthropic_num_threads: 2
openai_fraction_rate_limit: 0.9
