hydra:
  run:
    dir: ${exp_dir}/logs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${exp_dir}/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job_logging:
    root:
      level: INFO

defaults:
  - prompt: self_prediction_with_base_completion
  - language_model: gpt-3.5-turbo

# Common Params
strings_path: ${base_dir}/chosen_strings.csv # path to the strings file with the preselect strings for the experiment.
exp_dir: ${base_dir}_${language_model.model}_base_${dataset.n_shot}_shot_${dataset.n_shot_seeding}_seed
base_dir: ???  # path to the directory containing the base completions
seed: 0 # seed for the random number generator
base_seed: 0 # seed for the random number generator for the base completion
limit: 50 # how many?
reset: false
logging: INFO
print_prompt_and_response: false
cache_dir: ${exp_dir}/cache
prompt_history_dir: ${exp_dir}/prompt_history

# Model
language_model:
  temperature: 0.0
  logprobs: 5

# Extracting the most relevant strings from the base completion
dataset:
  num: ${limit}
  n_shot: 5 # set to 0 for zero-shot
  n_shot_seeding: true # true (takes inputs from basedir), scrambled (takes inputs from a random row of basedir), other_model (flag to use a different model BUT BASEDIR MUST BE SET TO THE MODEL YOU WANT TO USE)

# API
organization: OWAIN_ORG
anthropic_tag: ANTHROPIC_API_KEY
openai_tag: OPENAI_API_KEY
anthropic_num_threads: 1
openai_fraction_rate_limit: 0.9
