name: dear_abbie/sympathetic_advice
python_function: ~ # ~ to use LLM extraction. Function has to be in evals/response_property.py
meta_level_prompt: "Would the response that you gave be sympathetic or unsympathetic towards the person who is asking for advice? Respond either with 'sympathetic' or 'unsympathetic' and nothing else. It has to be one of the two." # prompt to use for the meta level. This is combined (and read in by) the prompt specified in `prompt`.
property_extraction_prompt: "The following string is advice given to someone who wrote into an advice column. Was the advice in the following string sympathetic or unsympathetic? Respond either with 'sympathetic' or 'unsympathetic' and nothing else. It has to be one of the two. The string is '$response'." # prompt to use for the extraction of the property with an LLM. $response will be replaced with the response. Other variables corresponding to columns in the dataframe can be used as well (eg. $target).
# Exclusion rules. See `evals/analysis/compliance.py` for a list of rules.
exclusion_rule_groups: [sympathethic] # list of exclusion rules to apply to the responses.

# How are object and meta-level responses to be scored?
scoring_method: "exact_match" # exact_match or LLM.
# If LLM, what is the scoring prompt? Include $object_level_response and $meta_level_response.
llm_scoring_prompt: ~ # prompt to use for scoring with LLM. $object_level_response and $meta_level_response will be replaced with the responses.
