name: kiki_bouba
python_function: ~ # ~ to use LLM extraction. Function has to be in evals/response_property.py
meta_level_prompt: "Would the response that you gave be classified as 'kiki' or 'bouba'? Respond either with 'kiki' or 'bouba' and nothing else. It has to be one of the two." # prompt to use for the meta level. This is combined (and read in by) the prompt specified in `prompt`.
property_extraction_prompt: "Would the following string be classified as 'kiki' or 'bouba'? Respond either with 'kiki' or 'bouba' and nothing else. It has to be one of the two. The string is '$response'." # prompt to use for the extraction of the property with an LLM. $response will be replaced with the response. Other variables corresponding to columns in the dataframe can be used as well (eg. $target).
# Exclusion rules. See `evals/analysis/compliance.py` for a list of rules.
exclusion_rule_groups: [kiki_bouba] # list of exclusion rules to apply to the responses.

# How are object and meta-level responses to be scored?
scoring_method: "exact_match" # exact_match or LLM.
# If LLM, what is the scoring prompt? Include $object_level_response and $meta_level_response.
llm_scoring_prompt: ~ # prompt to use for scoring with LLM. $object_level_response and $meta_level_response will be replaced with the responses.
